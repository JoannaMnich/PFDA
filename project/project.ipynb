{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c083569b",
   "metadata": {},
   "source": [
    "# Analysis of historic Irish weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd25f1e",
   "metadata": {},
   "source": [
    "## Author: Joanna Mnich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c138800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ab8d5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_station(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Clean a Met Éireann station CSV and save year, month, wdsp (mean wind speed).\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): path to raw CSV\n",
    "        output_path (str): path to save cleaned CSV\n",
    "    \"\"\"\n",
    "\n",
    "# Detect first row with actual numeric data (starts with a year)\n",
    "    data_row = None\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # skip empty lines, look for line starting with a digit (year)\n",
    "            if line.strip() and line.strip()[0].isdigit():\n",
    "                data_row = i\n",
    "                break\n",
    "\n",
    "    if data_row is None:\n",
    "        print(f\"No data found in {file_path}\")\n",
    "        return\n",
    "\n",
    "# Read CSV from detected data row\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=data_row,\n",
    "        header=None,\n",
    "        na_values=[\"---\", \"NaN\"],\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "\n",
    "# Assign proper column names (based on Met Éireann standard)\n",
    "    col_names = [\n",
    "        \"year\",\"month\",\"meant\",\"maxtp\",\"mintp\",\"mnmax\",\n",
    "        \"mnmin\",\"rain\",\"gmin\",\"wdsp\",\"maxgt\",\"sun\"\n",
    "    ][:df.shape[1]]  # adjust if file has fewer columns\n",
    "    df.columns = col_names\n",
    "    \n",
    "# Keep only relevant columns\n",
    "    df = df[[\"year\", \"month\", \"wdsp\"]]\n",
    "\n",
    "# Convert to numeric (coerce errors)\n",
    "    for col in [\"year\", \"month\", \"wdsp\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Filter years 2005–2025 and remove missing wdsp\n",
    "    df = df.dropna(subset=[\"wdsp\"])\n",
    "    df = df[(df[\"year\"] >= 2005) & (df[\"year\"] <= 2025)]\n",
    "\n",
    "# Save cleaned CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {output_path} — rows: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1a5e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/processed/Malin_Head_cleaned.csv — rows: 250\n",
      "Saved data/processed/Roches_Point_cleaned.csv — rows: 249\n",
      "Saved data/processed/Sherkin_Island_cleaned.csv — rows: 249\n",
      "Saved data/processed/Valentia_Observatory_cleaned.csv — rows: 249\n",
      "Saved data/processed/Dublin_Airport_cleaned.csv — rows: 251\n",
      "Saved data/processed/Phoenix_Park_cleaned.csv — rows: 2\n",
      "Saved data/processed/Casement_Aerodrome_cleaned.csv — rows: 251\n",
      "Saved data/processed/Belmullet_cleaned.csv — rows: 246\n",
      "Saved data/processed/Mullingar_cleaned.csv — rows: 251\n",
      "Saved data/processed/Claremorris_cleaned.csv — rows: 243\n"
     ]
    }
   ],
   "source": [
    "stations = {\n",
    "    \"Malin_Head\": \"Malin_Head.csv\",\n",
    "    \"Roches_Point\": \"Roches_point.csv\",\n",
    "    \"Sherkin_Island\": \"SherkinIsland.csv\",\n",
    "    \"Valentia_Observatory\": \"Valentia_Observatory.csv\",\n",
    "    \"Dublin_Airport\": \"Dublin_Airport.csv\",\n",
    "    \"Phoenix_Park\": \"Phoenix_Park.csv\",\n",
    "    \"Casement_Aerodrome\": \"Casement_Aerodrome.csv\",\n",
    "    \"Belmullet\": \"Belmullet.csv\",\n",
    "    \"Mullingar\": \"Mullingar.csv\",\n",
    "    \"Claremorris\": \"Claremorris.csv\"\n",
    "}\n",
    "\n",
    "for station, filename in stations.items():\n",
    "    clean_station(\n",
    "        file_path=f\"data/raw/{filename}\",\n",
    "        output_path=f\"data/processed/{station}_cleaned.csv\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_env)",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
